{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install facenet_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXOg8G9-eOA7",
        "outputId": "9d3ff0e3-0489-4af9-b254-cd67f1f26338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: facenet_pytorch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (1.26.4)\n",
            "Requirement already satisfied: Pillow<10.3.0,>=10.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (10.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (2.32.3)\n",
            "Requirement already satisfied: torch<2.3.0,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (2.2.2)\n",
            "Requirement already satisfied: torchvision<0.18.0,>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (0.17.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet_pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet_pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet_pytorch) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet_pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet_pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet_pytorch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JP3qWKfjdwad",
        "outputId": "42926cf2-e050-4c3c-9d9f-a76ba8c7fde7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using database at: /content/face_database.db\n",
            "Augmenting dataset with 5 synthetic samples per user...\n",
            "Training dataset: 72 face embeddings from 12 unique users\n",
            "Each user now has 6 samples (1 original + 5 augmented)\n",
            "Apply PCA for dimensionality reduction? (y/n): n\n",
            "Training SVM model...\n",
            "Minimum samples per user: 6\n",
            "Using 3-fold cross-validation\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "Best parameters found: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Model accuracy: 1.0000\n",
            "Model successfully trained and saved as 'face_model.pkl'\n",
            "\n",
            "Registered Users:\n",
            "1. Adeesha\n",
            "2. Avishka\n",
            "3. Chandima\n",
            "4. Maheesh\n",
            "5. Menuka\n",
            "6. Mubarak\n",
            "7. Tharindu\n",
            "8. isuru\n",
            "9. nadun\n",
            "10. nuwanthika\n",
            "11. ravindu\n",
            "12. shamal\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import sqlite3\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def train_face_recognition_model(augment_samples=True, num_augmented_samples=5):\n",
        "    \"\"\"\n",
        "    Train a custom SVM classifier using existing face embeddings from the database\n",
        "\n",
        "    Parameters:\n",
        "    augment_samples (bool): Whether to generate additional training samples through augmentation\n",
        "    num_augmented_samples (int): Number of augmented samples to create per user\n",
        "    \"\"\"\n",
        "    db_path = '/content/face_database.db'\n",
        "    print(f\"Using database at: {db_path}\")\n",
        "\n",
        "    try:\n",
        "        # Connect to the database\n",
        "        conn = sqlite3.connect(db_path)\n",
        "        cursor = conn.cursor()\n",
        "\n",
        "        # Fetch data from the users table\n",
        "        cursor.execute('SELECT id, facenet_embedding FROM users')\n",
        "\n",
        "        X = []  # embeddings\n",
        "        y = []  # labels\n",
        "\n",
        "        # Original embeddings\n",
        "        original_embeddings = {}\n",
        "\n",
        "        for row in cursor.fetchall():\n",
        "            user_id = row[0]\n",
        "            embedding = np.frombuffer(row[1], dtype=np.float32)\n",
        "\n",
        "            # Store the original embedding for each user\n",
        "            original_embeddings[user_id] = embedding\n",
        "\n",
        "            # Add original embedding to training data\n",
        "            X.append(embedding)\n",
        "            y.append(user_id)\n",
        "\n",
        "        conn.close()\n",
        "\n",
        "        # Perform data augmentation if enabled\n",
        "        if augment_samples:\n",
        "            print(f\"Augmenting dataset with {num_augmented_samples} synthetic samples per user...\")\n",
        "            for user_id, orig_embedding in original_embeddings.items():\n",
        "                # Create synthetic variations of each embedding\n",
        "                for i in range(num_augmented_samples):\n",
        "                    # Add small random noise to create variations (small % of feature magnitude)\n",
        "                    noise_scale = 0.02  # 2% noise\n",
        "                    noise = np.random.normal(0, noise_scale, size=orig_embedding.shape) * np.mean(np.abs(orig_embedding))\n",
        "                    augmented_embedding = orig_embedding + noise\n",
        "\n",
        "                    # Normalize the embedding to maintain unit length\n",
        "                    augmented_embedding = augmented_embedding / np.linalg.norm(augmented_embedding)\n",
        "\n",
        "                    # Add to training data\n",
        "                    X.append(augmented_embedding)\n",
        "                    y.append(user_id)\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        X = np.array(X)\n",
        "\n",
        "        print(f\"Training dataset: {len(X)} face embeddings from {len(original_embeddings)} unique users\")\n",
        "        if augment_samples:\n",
        "            print(f\"Each user now has {1 + num_augmented_samples} samples (1 original + {num_augmented_samples} augmented)\")\n",
        "\n",
        "        # Optional: Apply PCA for dimensionality reduction\n",
        "        apply_pca = input(\"Apply PCA for dimensionality reduction? (y/n): \").lower() == 'y'\n",
        "        if apply_pca:\n",
        "            # Keep 95% of variance\n",
        "            pca = PCA(n_components=0.95)\n",
        "            X_reduced = pca.fit_transform(X)\n",
        "            print(f\"Reduced dimensions from {X.shape[1]} to {X_reduced.shape[1]} features\")\n",
        "\n",
        "            # Save the PCA model\n",
        "            with open('face_pca.pkl', 'wb') as f:\n",
        "                pickle.dump(pca, f)\n",
        "            print(\"PCA model saved as 'face_pca.pkl'\")\n",
        "\n",
        "            # Use reduced features for training\n",
        "            X = X_reduced\n",
        "\n",
        "        # Encode user labels\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "        print(f\"Training SVM model...\")\n",
        "\n",
        "        # Check how many samples per class we have\n",
        "        unique_users, counts = np.unique(y, return_counts=True)\n",
        "        min_samples = np.min(counts)\n",
        "\n",
        "        print(f\"Minimum samples per user: {min_samples}\")\n",
        "\n",
        "        # Parameter grid for SVM\n",
        "        param_grid = {\n",
        "            'C': [0.1, 1, 10, 100],\n",
        "            'kernel': ['linear', 'rbf'],\n",
        "            'gamma': ['scale', 'auto', 0.01]\n",
        "        }\n",
        "\n",
        "        # Choose appropriate cross-validation strategy\n",
        "        if min_samples < 3:\n",
        "            print(\"Using leave-one-out cross-validation\")\n",
        "            cv = LeaveOneOut()\n",
        "        else:\n",
        "            cv_folds = min(3, min_samples)\n",
        "            print(f\"Using {cv_folds}-fold cross-validation\")\n",
        "            cv = cv_folds\n",
        "\n",
        "        try:\n",
        "            grid_search = GridSearchCV(\n",
        "                SVC(probability=True),\n",
        "                param_grid,\n",
        "                cv=cv,\n",
        "                n_jobs=-1,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X, y_encoded)\n",
        "            best_model = grid_search.best_estimator_\n",
        "\n",
        "            print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "            print(f\"Model accuracy: {grid_search.best_score_:.4f}\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Cross-validation failed: {e}\")\n",
        "            print(\"Training model without cross-validation...\")\n",
        "\n",
        "            # Fallback to a simple model without cross-validation\n",
        "            best_model = SVC(probability=True, C=1, kernel='linear', gamma='scale')\n",
        "            best_model.fit(X, y_encoded)\n",
        "            print(\"Model trained without validation\")\n",
        "\n",
        "        # Save the model and label encoder\n",
        "        with open('face_model.pkl', 'wb') as f:\n",
        "            pickle.dump((best_model, label_encoder), f)\n",
        "\n",
        "        print(\"Model successfully trained and saved as 'face_model.pkl'\")\n",
        "\n",
        "        # Print registered users for reference\n",
        "        print(\"\\nRegistered Users:\")\n",
        "        for i, user_id in enumerate(label_encoder.classes_):\n",
        "            print(f\"{i+1}. {user_id}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set to True to generate synthetic samples\n",
        "    train_face_recognition_model(augment_samples=True, num_augmented_samples=5)"
      ]
    }
  ]
}